{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cd5933",
   "metadata": {},
   "source": [
    "# Text Analytics - Assignment 4 \n",
    "# NLP (Text Classification) With Recurrent Neural Nets\n",
    "\n",
    "---\n",
    "\n",
    "> Kostis Konstantinos (p3352311) <br>\n",
    "> MSc Data-Science (Part-Time) <br>\n",
    "> Athens University Of Economics and Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries (via pip) for Google Colab\n",
    "\n",
    "# !pip install -U conllu gensim pandas requests tensorflow==2.15.0 keras-tuner scikit-learn matplotlib ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccd14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "# INFO, WARNING and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "\n",
    "from io import open\n",
    "from collections import Counter\n",
    "\n",
    "from conllu import parse_incr\n",
    "import requests\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Input, Embedding,\n",
    "                                     Bidirectional, GRU, TimeDistributed)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from sklearn.metrics import (f1_score, recall_score, precision_score, \n",
    "                             auc, precision_recall_curve)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffefdf",
   "metadata": {},
   "source": [
    "### Setting a random seed (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc78ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2af0c",
   "metadata": {},
   "source": [
    "### Dataset (Description & Helper Classes)\n",
    "\n",
    "The dataset used, refers to the english language of the Universal Dependencies tree banks and more specifically GUM from Georgetown University.\n",
    "It contains 10761 sentences from different genres: academic, blog, fiction, government, news, nonfiction, social, spoken, web, wiki.\n",
    "The dataset is downloaded from Github and parsed using the conllu package, via a custom class named DatasetHandler.\n",
    "\n",
    "Treebank index page can be found here https://universaldependencies.org/treebanks/en_gum/index.html \\\n",
    "The actual data (train, dev, test) files can be found at https://github.com/UniversalDependencies/UD_English-GUM/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09786314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse train, dev and test splits (download from github)\n",
    "\n",
    "class DatasetHandler:\n",
    "    \"\"\" DatasetHandler\n",
    "    \n",
    "    Downloads and parses the universal-dependencies/en-gmu data files.\n",
    "    \"\"\"\n",
    "    def __init__(self, url, mode):\n",
    "        self.url = url\n",
    "        self.mode = mode\n",
    "\n",
    "        self.sentences = []\n",
    "        \n",
    "        self.data_directory = 'data'\n",
    "        self.data_file = os.path.join(self.data_directory, \"{}.conllu\".format(self.mode))\n",
    "\n",
    "    def fetch(self):\n",
    "        if not os.path.exists(self.data_directory):\n",
    "            os.makedirs(self.data_directory)\n",
    "\n",
    "        if not os.path.exists(self.data_file):\n",
    "            self.download()\n",
    "\n",
    "        handle = open(self.data_file, \"r\", encoding=\"utf-8\")\n",
    "        for tokenlist in parse_incr(handle):\n",
    "            sentence = []\n",
    "\n",
    "            for token in tokenlist:\n",
    "                if not token['form']:\n",
    "                    continue\n",
    "                sentence.append((token['form'].lower(), token['upos']))\n",
    "\n",
    "            self.sentences.append(sentence)\n",
    "\n",
    "    def basic_stats(self):\n",
    "        n_sentences = len(self.sentences)\n",
    "\n",
    "        words = []\n",
    "        average_sentence_length = 0\n",
    "\n",
    "        for sentence in self.sentences:\n",
    "            average_sentence_length += len(sentence)\n",
    "\n",
    "            for item in sentence:\n",
    "                words.append(item[0])\n",
    "\n",
    "        average_sentence_length /= n_sentences \n",
    "\n",
    "        n_words = len(words)\n",
    "        n_unique_words = len(set(words))\n",
    "\n",
    "        stats = [[self.mode, n_sentences, round(average_sentence_length,1), n_words, n_unique_words]]\n",
    "        df = pd.DataFrame(stats, columns=['Dataset', 'Sentences', 'Average Sentence Length', 'Words', 'Unique Words'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def download(self):\n",
    "        response = requests.get(self.url)\n",
    "        with open(self.data_file, mode=\"wb\") as file:\n",
    "            file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b160af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceUtils:\n",
    "    \"\"\"Sentence utility methods.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_of(tagged_sentence):\n",
    "        return [token for (token, tag) in tagged_sentence]\n",
    "\n",
    "    @staticmethod\n",
    "    def pos_of(tagged_sentence):\n",
    "        return [tag for (token, tag) in tagged_sentence]\n",
    "\n",
    "    @staticmethod\n",
    "    def texts(sentences):\n",
    "        return [ __class__.tokens_of(sentence) for sentence in sentences]\n",
    "\n",
    "    @staticmethod\n",
    "    def tags(sentences):\n",
    "        return [ __class__.pos_of(sentence) for sentence in sentences]\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_texts(sentences):\n",
    "        return [token\n",
    "                for tokenList in __class__.texts(sentences)\n",
    "                for token in tokenList]\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten_tags(sentences):\n",
    "        return [tag \n",
    "                for tagList in __class__.tags(sentences)\n",
    "                for tag in tagList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2128ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch/Parse the data\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-train.conllu'\n",
    "dev_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-dev.conllu'\n",
    "test_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/master/en_gum-ud-test.conllu'\n",
    "\n",
    "train_ds_handler = DatasetHandler(train_url, 'train')\n",
    "train_ds_handler.fetch()\n",
    "\n",
    "dev_ds_handler = DatasetHandler(dev_url, 'dev')\n",
    "dev_ds_handler.fetch()\n",
    "\n",
    "test_ds_handler = DatasetHandler(test_url, 'test')\n",
    "test_ds_handler.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162584c",
   "metadata": {},
   "source": [
    "### Basic statistics\n",
    "\n",
    "Below you can find some basic statistics regarding the train, dev and test sets. Reported statistics are:\n",
    "\n",
    "- Dataset split\n",
    "- Number of sentences\n",
    "- Average sentence length\n",
    "- Number of words\n",
    "- Number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2caeebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Unique Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>9521</td>\n",
       "      <td>17.5</td>\n",
       "      <td>166918</td>\n",
       "      <td>15555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>1341</td>\n",
       "      <td>18.2</td>\n",
       "      <td>24375</td>\n",
       "      <td>4302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>1285</td>\n",
       "      <td>18.9</td>\n",
       "      <td>24330</td>\n",
       "      <td>4819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Sentences  Average Sentence Length   Words  Unique Words\n",
       "0   train       9521                     17.5  166918         15555\n",
       "1     dev       1341                     18.2   24375          4302\n",
       "2    test       1285                     18.9   24330          4819"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = train_ds_handler.basic_stats()\n",
    "dev_stats = dev_ds_handler.basic_stats()\n",
    "test_stats = test_ds_handler.basic_stats()\n",
    "\n",
    "stats = pd.concat([train_stats, dev_stats, test_stats], ignore_index=True)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c92383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aesthetic', 'ADJ'),\n",
       " ('appreciation', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('spanish', 'ADJ'),\n",
       " ('art', 'NOUN'),\n",
       " (':', 'PUNCT')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_handler.sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cbea4e",
   "metadata": {},
   "source": [
    "### Helper method for generating a classification report\n",
    "\n",
    "This section refers to an implementation of a method that produces a classification report\n",
    "for a given dataset. The dimensions of this report include:\n",
    "\n",
    "- Precision (For each POS tag)\n",
    "- Recall (For each POS tag)\n",
    "- F1 (For each POS tag)\n",
    "- Precision-Recall AUC (For each POS Tag)\n",
    "- Macro avegerages for the above metrics\n",
    "\n",
    "The report is given as pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ec4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report implementation\n",
    "class EvaluationMetrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def classification_report(y_true, y_probabilities, y_predicted, class_ids, class_labels):\n",
    "        \"\"\" Creates a classification report for a multi-class classsification problem.\n",
    "\n",
    "        Note: Scikit-Learn's precision_recall_curve has its output reversed. See:\n",
    "        https://github.com/scikit-learn/scikit-learn/issues/2097\n",
    "        \n",
    "        Args:\n",
    "            y_true: A one dimensional array(n_samples), containing the actual class id per sample.\n",
    "            y_probabilities: A 2D array (n_samples, n_classes) containing the predicted probabilities\n",
    "                per sample.\n",
    "            y_predicted: A one dimensional array(n_samples) containing the predicted class id per sample.\n",
    "            class_ids: A one dimensional array (n_classes) containing the ids of classes.\n",
    "            class_labels: A one dimensional array (n_classes) containing the names of the classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute precision (per class)\n",
    "        precision = precision_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute recall (per class)\n",
    "        recall = recall_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute F1 (per class)\n",
    "        f1 = f1_score(y_true, y_predicted, average=None)\n",
    "\n",
    "        # Compute Precision-Recall AUC score (per class)\n",
    "        auc_scores = []\n",
    "        for class_id in class_ids:\n",
    "            class_indices = (y_true == class_id)\n",
    "            if any(class_indices):\n",
    "                class_precision, class_recall, thresholds = precision_recall_curve(\n",
    "                    class_indices.astype(int), y_probabilities[:, class_id])\n",
    "                class_precision_recall_auc = auc(class_recall, class_precision)\n",
    "                auc_scores.append(class_precision_recall_auc)\n",
    "\n",
    "        classification_report_df = pd.DataFrame()\n",
    "        classification_report_df['Class Id'] = class_ids\n",
    "        classification_report_df['Class Name'] = class_labels\n",
    "        classification_report_df['Precision'] = precision\n",
    "        classification_report_df['Recall'] = recall\n",
    "        classification_report_df['F1'] = f1\n",
    "        classification_report_df['Precision-Recall AUC'] = auc_scores\n",
    "    \n",
    "        macro_average_df = pd.DataFrame()\n",
    "        macro_average_df['Macro Average Precision'] = [np.mean(precision)]\n",
    "        macro_average_df['Macro Average Recall'] = [np.mean(recall)]\n",
    "        macro_average_df['Macro Average F1'] = [np.mean(f1)]\n",
    "        macro_average_df['Macro Average Precision Recall AUC'] = [np.mean(auc_scores)]\n",
    "    \n",
    "        return (classification_report_df, macro_average_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf5191",
   "metadata": {},
   "source": [
    "## POS Tagger: Baseline Classifier (most frequent tag)\n",
    "\n",
    "**Important:**\n",
    "The baseline is re-implemented in order to correctly report the needed metrics (precision, recall, f1, precision-recall AUC)\n",
    "for all data subsets (train, dev, test). \\\n",
    "This is done because in the previous assignment (Text Classification with MLPs)\n",
    "we did not report the precision-recall AUC for the baseline (most-frequent-tag classifier).\\\n",
    "The MLP-Tagger is not re-implemented since all the metrics were correctly presented in the PDF report.\n",
    "\n",
    "This section implements a baseline classifier, that utilizes the most frequent tag (POS tag) given a word.\\\n",
    "Essentially, fitting the baseline simply means counting the occurencies of (word, tag) pairs.\\\n",
    "Consequently, during inference when a word is given the most frequent tag of the word is selected.\\\n",
    "In case the given word was not seen in the training set, then the most frequent tag over all tags is selected.\\\n",
    "This is a custom implementation with a Scikit-Learn compatible interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a179e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (Most frequent tag) implementation\n",
    "class MostFrequentTagClassifier:\n",
    "    def __init__(self):\n",
    "        self.word2tag = {}\n",
    "        self.most_frequent_tag = None\n",
    "        self.tag2id = {}\n",
    "\n",
    "    def fit(self, X):\n",
    "        pair_frequencies = {}\n",
    "        tag_frequencies = Counter()\n",
    "\n",
    "        # Collect counts for tags and pairs of word/tag\n",
    "        for sentence in X:\n",
    "            for (word, tag) in sentence:\n",
    "                if word not in pair_frequencies:\n",
    "                    pair_frequencies[word] = Counter()\n",
    "                pair_frequencies[word][tag] += 1\n",
    "                tag_frequencies[tag] += 1\n",
    "\n",
    "        # Persist the overall most frequent tag and the most frequent tag per word\n",
    "        self.most_frequent_tag = tag_frequencies.most_common()[0][0]\n",
    "        for word in pair_frequencies.keys():\n",
    "            self.word2tag[word] = pair_frequencies[word].most_common()[0][0]\n",
    "\n",
    "        tags = list(tag_frequencies.keys())\n",
    "        self.tag2id = {tag: idx for (idx, tag) in enumerate(tags)}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, word):\n",
    "        prediction = None\n",
    "\n",
    "        if word not in self.word2tag:\n",
    "            prediction = self.most_frequent_tag\n",
    "        else:\n",
    "            prediction = self.word2tag[word]\n",
    "\n",
    "        return self.tag2id[prediction]\n",
    "\n",
    "    def predict_proba(self, word):\n",
    "        prediction = self.predict(word)\n",
    "\n",
    "        return to_categorical([prediction], num_classes=len(self.tag2id))\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        tokens = SentenceUtils.flatten_texts(dataset)\n",
    "        tags = SentenceUtils.flatten_tags(dataset)\n",
    "\n",
    "        y_true = np.array([self.tag2id[tag] for tag in tags])\n",
    "        y_predicted = np.array([self.predict(token) for token in tokens])\n",
    "\n",
    "        y_probabilities = []\n",
    "        for token in tokens:\n",
    "            y_probabilities.append(self.predict_proba(token))\n",
    "        y_probabilities = np.array(y_probabilities).reshape((len(tokens), len(self.tag2id)))\n",
    "\n",
    "        class_ids = list(self.tag2id.values())\n",
    "        class_labels = list(self.tag2id.keys())\n",
    "\n",
    "        return EvaluationMetrics.classification_report(\n",
    "            y_true, y_probabilities, y_predicted, class_ids, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9b784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit the MostFrequentTagClassifier\n",
    "most_frequent_tag_classifier = MostFrequentTagClassifier().fit(train_ds_handler.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63951288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline evaluation (train set)\n",
    "train_set = train_ds_handler.sentences\n",
    "train_classification_report_df, train_macro_average_df = most_frequent_tag_classifier.evaluate(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0088d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.905493</td>\n",
       "      <td>0.932019</td>\n",
       "      <td>0.918565</td>\n",
       "      <td>0.920946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.923814</td>\n",
       "      <td>0.939181</td>\n",
       "      <td>0.931434</td>\n",
       "      <td>0.936470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.990724</td>\n",
       "      <td>0.992565</td>\n",
       "      <td>0.992718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.995007</td>\n",
       "      <td>0.998593</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.996896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.905744</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.897087</td>\n",
       "      <td>0.902333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.924751</td>\n",
       "      <td>0.828910</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>0.881716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.898068</td>\n",
       "      <td>0.910544</td>\n",
       "      <td>0.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.915924</td>\n",
       "      <td>0.824751</td>\n",
       "      <td>0.867950</td>\n",
       "      <td>0.874456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.870135</td>\n",
       "      <td>0.947965</td>\n",
       "      <td>0.907384</td>\n",
       "      <td>0.910425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.946340</td>\n",
       "      <td>0.977793</td>\n",
       "      <td>0.961810</td>\n",
       "      <td>0.962953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.920814</td>\n",
       "      <td>0.957455</td>\n",
       "      <td>0.938777</td>\n",
       "      <td>0.940893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.804577</td>\n",
       "      <td>0.345166</td>\n",
       "      <td>0.483087</td>\n",
       "      <td>0.580066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "      <td>0.954918</td>\n",
       "      <td>0.732704</td>\n",
       "      <td>0.829181</td>\n",
       "      <td>0.844066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.831712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.698403</td>\n",
       "      <td>0.900381</td>\n",
       "      <td>0.786634</td>\n",
       "      <td>0.800566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>_</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.999294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.953790</td>\n",
       "      <td>0.996843</td>\n",
       "      <td>0.974842</td>\n",
       "      <td>0.975347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.858573</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.793696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        ADJ   0.905493  0.932019  0.918565              0.920946\n",
       "1          1       NOUN   0.923814  0.939181  0.931434              0.936470\n",
       "2          2      CCONJ   0.994413  0.990724  0.992565              0.992718\n",
       "3          3      PUNCT   0.995007  0.998593  0.996797              0.996896\n",
       "4          4        ADP   0.905744  0.888595  0.897087              0.902333\n",
       "5          5      PROPN   0.924751  0.828910  0.874212              0.881716\n",
       "6          6       VERB   0.923371  0.898068  0.910544              0.915968\n",
       "7          7        ADV   0.915924  0.824751  0.867950              0.874456\n",
       "8          8        AUX   0.870135  0.947965  0.907384              0.910425\n",
       "9          9        DET   0.946340  0.977793  0.961810              0.962953\n",
       "10        10       PRON   0.920814  0.957455  0.938777              0.940893\n",
       "11        11      SCONJ   0.804577  0.345166  0.483087              0.580066\n",
       "12        12          X   0.954918  0.732704  0.829181              0.844066\n",
       "13        13        SYM   0.941176  0.721805  0.817021              0.831712\n",
       "14        14       PART   0.698403  0.900381  0.786634              0.800566\n",
       "15        15          _   0.999288  0.999288  0.999288              0.999294\n",
       "16        16        NUM   0.953790  0.996843  0.974842              0.975347\n",
       "17        17       INTJ   0.727466  0.858573  0.787600              0.793696"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c91db1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.874379</td>\n",
       "      <td>0.881932</td>\n",
       "      <td>0.892251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.905857              0.874379          0.881932   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.892251  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_macro_average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f842fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline evaluation (dev set)\n",
    "dev_set = dev_ds_handler.sentences\n",
    "dev_classification_report_df, dev_macro_average_df = most_frequent_tag_classifier.evaluate(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378bf494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.891349</td>\n",
       "      <td>0.813131</td>\n",
       "      <td>0.850446</td>\n",
       "      <td>0.858312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.735206</td>\n",
       "      <td>0.925740</td>\n",
       "      <td>0.819545</td>\n",
       "      <td>0.836545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.993925</td>\n",
       "      <td>0.987923</td>\n",
       "      <td>0.990915</td>\n",
       "      <td>0.991129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.995926</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.997646</td>\n",
       "      <td>0.997690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.910087</td>\n",
       "      <td>0.895777</td>\n",
       "      <td>0.902875</td>\n",
       "      <td>0.907691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.779174</td>\n",
       "      <td>0.422179</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.612861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.906886</td>\n",
       "      <td>0.782219</td>\n",
       "      <td>0.839952</td>\n",
       "      <td>0.856511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.906218</td>\n",
       "      <td>0.772372</td>\n",
       "      <td>0.833959</td>\n",
       "      <td>0.844669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.942350</td>\n",
       "      <td>0.906506</td>\n",
       "      <td>0.909419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.950231</td>\n",
       "      <td>0.976793</td>\n",
       "      <td>0.963329</td>\n",
       "      <td>0.964415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.920050</td>\n",
       "      <td>0.964458</td>\n",
       "      <td>0.941731</td>\n",
       "      <td>0.943916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>SYM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.700185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>0.916793</td>\n",
       "      <td>0.813969</td>\n",
       "      <td>0.825467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>_</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>0.942686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.869792</td>\n",
       "      <td>0.910082</td>\n",
       "      <td>0.913064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.718644</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.769510</td>\n",
       "      <td>0.774287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        ADJ   0.891349  0.813131  0.850446              0.858312\n",
       "1          1       NOUN   0.735206  0.925740  0.819545              0.836545\n",
       "2          2      CCONJ   0.993925  0.987923  0.990915              0.991129\n",
       "3          3      PUNCT   0.995926  0.999371  0.997646              0.997690\n",
       "4          4        ADP   0.910087  0.895777  0.902875              0.907691\n",
       "5          5      PROPN   0.779174  0.422179  0.547634              0.612861\n",
       "6          6       VERB   0.906886  0.782219  0.839952              0.856511\n",
       "7          7        ADV   0.906218  0.772372  0.833959              0.844669\n",
       "8          8        AUX   0.873288  0.942350  0.906506              0.909419\n",
       "9          9        DET   0.950231  0.976793  0.963329              0.964415\n",
       "10        10       PRON   0.920050  0.964458  0.941731              0.943916\n",
       "11        11      SCONJ   0.837209  0.356436  0.500000              0.602156\n",
       "12        12          X   1.000000  0.500000  0.666667              0.750123\n",
       "13        13        SYM   1.000000  0.400000  0.571429              0.700185\n",
       "14        14       PART   0.731884  0.916793  0.813969              0.825467\n",
       "15        15          _   0.997525  0.885714  0.938300              0.942686\n",
       "16        16        NUM   0.954286  0.869792  0.910082              0.913064\n",
       "17        17       INTJ   0.718644  0.828125  0.769510              0.774287"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b6a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.894549</td>\n",
       "      <td>0.791065</td>\n",
       "      <td>0.82025</td>\n",
       "      <td>0.846174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.894549              0.791065           0.82025   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.846174  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_macro_average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1094d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline evaluation (test set)\n",
    "test_set = test_ds_handler.sentences\n",
    "test_classification_report_df, test_macro_average_df = most_frequent_tag_classifier.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23bd1292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.883056</td>\n",
       "      <td>0.819359</td>\n",
       "      <td>0.850016</td>\n",
       "      <td>0.857229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.683357</td>\n",
       "      <td>0.924039</td>\n",
       "      <td>0.785678</td>\n",
       "      <td>0.810315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.995140</td>\n",
       "      <td>0.976162</td>\n",
       "      <td>0.985560</td>\n",
       "      <td>0.986062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0.994726</td>\n",
       "      <td>0.997027</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.996062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0.908833</td>\n",
       "      <td>0.904071</td>\n",
       "      <td>0.906446</td>\n",
       "      <td>0.911343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.802910</td>\n",
       "      <td>0.372850</td>\n",
       "      <td>0.509228</td>\n",
       "      <td>0.608862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0.887750</td>\n",
       "      <td>0.768548</td>\n",
       "      <td>0.823860</td>\n",
       "      <td>0.839946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0.917869</td>\n",
       "      <td>0.742370</td>\n",
       "      <td>0.820844</td>\n",
       "      <td>0.836018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0.876466</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.908428</td>\n",
       "      <td>0.911035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.956161</td>\n",
       "      <td>0.981525</td>\n",
       "      <td>0.968677</td>\n",
       "      <td>0.969644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.913067</td>\n",
       "      <td>0.968499</td>\n",
       "      <td>0.939967</td>\n",
       "      <td>0.941913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.488421</td>\n",
       "      <td>0.604821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.675901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.894027</td>\n",
       "      <td>0.773978</td>\n",
       "      <td>0.789320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>_</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747692</td>\n",
       "      <td>0.855634</td>\n",
       "      <td>0.875531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.885086</td>\n",
       "      <td>0.891803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0.756760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          0        ADJ   0.883056  0.819359  0.850016              0.857229\n",
       "1          1       NOUN   0.683357  0.924039  0.785678              0.810315\n",
       "2          2      CCONJ   0.995140  0.976162  0.985560              0.986062\n",
       "3          3      PUNCT   0.994726  0.997027  0.995875              0.996062\n",
       "4          4        ADP   0.908833  0.904071  0.906446              0.911343\n",
       "5          5      PROPN   0.802910  0.372850  0.509228              0.608862\n",
       "6          6       VERB   0.887750  0.768548  0.823860              0.839946\n",
       "7          7        ADV   0.917869  0.742370  0.820844              0.836018\n",
       "8          8        AUX   0.876466  0.942809  0.908428              0.911035\n",
       "9          9        DET   0.956161  0.981525  0.968677              0.969644\n",
       "10        10       PRON   0.913067  0.968499  0.939967              0.941913\n",
       "11        11      SCONJ   0.859259  0.341176  0.488421              0.604821\n",
       "12        12          X   0.882353  0.468750  0.612245              0.675901\n",
       "13        13        SYM   0.818182  0.514286  0.631579              0.666583\n",
       "14        14       PART   0.682353  0.894027  0.773978              0.789320\n",
       "15        15          _   1.000000  0.747692  0.855634              0.875531\n",
       "16        16        NUM   0.957672  0.822727  0.885086              0.891803\n",
       "17        17       INTJ   0.696335  0.815951  0.751412              0.756760"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9938802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.873083</td>\n",
       "      <td>0.777882</td>\n",
       "      <td>0.805163</td>\n",
       "      <td>0.829397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.873083              0.777882          0.805163   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.829397  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_macro_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1488ba",
   "metadata": {},
   "source": [
    "## POS Tagger: Building an RNN\n",
    "\n",
    "In this section we build an RNN (Recurrent Neural Network) to deal with the part-of-speech tagging problem.\\\n",
    "This is different than the MLPs, because the input here is a sequence, of words (converted to integer positions of the vocabulary)\\\n",
    "and the ouput is also a sequence, of tags/classes. Hence, this is a many-to-many problem.\n",
    "\n",
    "Classes are constructed in order to reduce code duplication allowing for reusability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec49d8",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "- Define a vocabulary size and the maximum sequence length.\n",
    "- Divide the data into words (X: input sequences) and tags (Y: output sequences) (ensuring their lengths are equal) \n",
    "- Vectorizing X and Y (using the Tokenizer object) and by appropriately padding input/output sequences using the maximum sequence length.\n",
    "- Loading and using pre-trained word embeddings to transform the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1a3a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size (taken from stats dataframe)\n",
    "# +2 refers to the OOV (__UNK__) and PADDED words\n",
    "# (which are both mapped to zero)\n",
    "VOCABULARY_SIZE = stats.iloc[0]['Unique Words'] + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d05efce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum sequence length to use.\n",
    "\n",
    "# First find the maximum length of train sequences\n",
    "text_lengths = [len(text) for text in SentenceUtils.texts(train_ds_handler.sentences)]\n",
    "max_len = np.max(text_lengths)\n",
    "\n",
    "# Find the number which is a power of 2 and it is closer to max_len\n",
    "a = np.log2(max_len) - np.floor(np.log2(max_len))\n",
    "b = np.ceil(np.log2(max_len)) - np.log2(max_len)\n",
    "\n",
    "if a < b:\n",
    "    max_seq_len = 2**np.floor(np.log2(max_len))\n",
    "else:\n",
    "    max_seq_len = 2**np.ceil(np.log2(max_len))\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = int(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89a7faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\" A data processor with a Scikit-Learn like interface.\n",
    "\n",
    "    The class is responsible for processing a dataset, by using a Tokenizer\n",
    "    on input texts, converting labels to ids (different Tokenizer) and\n",
    "    padding sequences appropriately.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocabulary_size=VOCABULARY_SIZE, max_sequence_length=MAX_SEQUENCE_LENGTH, padded_label_value=-1):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.word_tokenizer = Tokenizer(num_words=VOCABULARY_SIZE, oov_token='__UNK__')\n",
    "        self.tag_tokenizer = Tokenizer()\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        X = SentenceUtils.texts(dataset)\n",
    "        Y = SentenceUtils.tags(dataset)\n",
    "\n",
    "        assert len(X) == len(Y)\n",
    "        for idx in range(0, len(X)):\n",
    "            assert len(X[idx]) == len(Y[idx])\n",
    "\n",
    "        self.word_tokenizer.fit_on_texts(X)\n",
    "        self.tag_tokenizer.fit_on_texts(Y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        \"\"\" Transform the given dataset \n",
    "\n",
    "        Encode and pad/truncate the input sequences (X)\n",
    "        Encode the labels (id assignment)\n",
    "        \"\"\"\n",
    "        X = SentenceUtils.texts(dataset)\n",
    "        X_encoded = self.word_tokenizer.texts_to_sequences(X)\n",
    "\n",
    "        Y = SentenceUtils.tags(dataset)\n",
    "        Y_encoded = self.tag_tokenizer.texts_to_sequences(Y)\n",
    "\n",
    "        X_padded = pad_sequences(X_encoded, maxlen=self.max_sequence_length, padding='post')\n",
    "        Y_padded = pad_sequences(Y_encoded, maxlen=self.max_sequence_length, padding='post')\n",
    "\n",
    "        return (X_padded, Y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9134f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataProcessor and fit on the train sentences\n",
    "data_processor = DataProcessor().fit(train_ds_handler.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0489b4",
   "metadata": {},
   "source": [
    "### Loading the embeddings model and constructing the embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc16f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings from gensim\n",
    "embedding_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "EMBEDDING_DIMENSIONS = embedding_model.get_vector('happy').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9cb8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros(shape=(VOCABULARY_SIZE, EMBEDDING_DIMENSIONS))\n",
    "\n",
    "for w2idx, _word in data_processor.word_tokenizer.index_word.items():\n",
    "    # Skip PAD and UNK tokens\n",
    "    if w2idx < 2:\n",
    "      continue\n",
    "    try:\n",
    "        embedding_matrix[w2idx] = embedding_model[_word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d7e32",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "- Number of Bi-directional RNNs to stack (Values: 2, 3, 4)\n",
    "- The memory size (hidden state) of the GRU Block (Range: [64,256], with step 32)\n",
    "- Dropout probabilities ( Values: 0.1, 0.2, 0.3, 0.4, 0.5) between layers\n",
    "- Learning rate of the Adam Optimizer (Values: 0.01, 0.001, or 0.0001)\n",
    "\n",
    "Since GRUs run faster than LSTMs, the GRU is used. Also recurrent_dropout is not used since it makes the network to train slower.\n",
    "\n",
    "Tuning is realized via a class named `RNNTaggerTuner`.\\\n",
    "Keras-Tuner is used to perform a randomized search on the hyperparamters space.\n",
    "The setup includes 5 trials at maximum, using 20 epochs and a batch size of 128 sentences.\\\n",
    "A fraction of the training data (40%) is used for finetuning.\n",
    "The objective of the tuner is to maximize the validation sparse categorical accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f24ee8",
   "metadata": {},
   "source": [
    "### A note on sparse categorical cross-entropy\n",
    "In this exercise (POS Tagger with RNN) the loss used is set to be `sparse categorical cross entropy`. This is convenient to us,\n",
    "because only the ids of the labels are given as targets when training. Tensorflow internally, converts these ids\n",
    "into their one-hot encoded format and essentially it runs the `categorical cross entropy` loss. On the way out, Tensorflow\n",
    "re-converts the one-hot encoded labels into their ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "986773f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTaggerTuner:\n",
    "    def __init__(self, train_sentences, dev_sentences, data_processor,\n",
    "                 embedding_matrix, n_stacked, train_size=0.5, seed=seed):\n",
    "        self.data_processor = data_processor\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_dimensions = embedding_matrix.shape[-1]\n",
    "        self.n_stacked = n_stacked\n",
    "        self.seed = seed\n",
    "        \n",
    "        # +1 refers to class with id zero (0) which should correspond to masked\n",
    "        # (zeroed) input, for which we do not care.\n",
    "        self.num_classes = len(self.data_processor.tag_tokenizer.word_index) + 1\n",
    "\n",
    "        train_X, train_y = data_processor.transform(train_sentences)\n",
    "        sample_size = int(len(train_X) * train_size)\n",
    "\n",
    "        self.train_X = train_X[0:sample_size+1]\n",
    "        self.train_y = train_y[0:sample_size+1]\n",
    "\n",
    "        dev_X, dev_y = data_processor.transform(dev_sentences)\n",
    "        self.dev_X = dev_X\n",
    "        self.dev_y = dev_y\n",
    "        # self.dev_y = to_categorical(dev_y, num_classes=self.num_classes)\n",
    "\n",
    "    def tune(self, max_trials=3, epochs=30):\n",
    "        tuner = kt.RandomSearch(self.build_model, \n",
    "                                objective=kt.Objective(\"val_sparse_categorical_accuracy\", direction=\"max\"),\n",
    "                                max_trials = max_trials,\n",
    "                                seed=self.seed,\n",
    "                                directory='KT_dir',\n",
    "                                project_name=\"KT_rnn_pos_nstacked_{}\".format(self.n_stacked))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "        tuner.search(self.train_X, self.train_y,\n",
    "                     validation_data=(self.dev_X, self.dev_y),\n",
    "                     epochs=epochs, batch_size = 128,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "        return tuner\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Input(shape=(self.data_processor.max_sequence_length,)))\n",
    "        model.add(Embedding(self.data_processor.vocabulary_size,\n",
    "                            self.embedding_dimensions,\n",
    "                            weights=[self.embedding_matrix],\n",
    "                            input_length=self.data_processor.max_sequence_length,\n",
    "                            mask_zero=True, trainable=False))\n",
    "        model.add(Dropout(hp.Choice(name='dropout_layer_first',values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "\n",
    "        for i in range(0, self.n_stacked):\n",
    "            hp_gru_units = hp.Int('gru_units_'+str(i), min_value=64, max_value=256, step=32)\n",
    "            hp_dropout = hp.Choice(name='dropout_layer_'+str(i), values=[0.1,0.2,0.3,0.4,0.5])\n",
    "\n",
    "            model.add(Bidirectional(GRU(hp_gru_units, return_sequences=True)))\n",
    "            model.add(Dropout(hp_dropout))\n",
    "            \n",
    "        model.add(Dense(units=1_000, activation='relu' ))\n",
    "        model.add(Dropout(hp.Choice(name='dropout_layer_last',values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(self.num_classes, activation='softmax')))\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        model.compile(loss=sparse_categorical_crossentropy, \n",
    "                      optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                      metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "662cd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run tuning for 2 stacked bidirectional RNNs\n",
    "# rnn_tuner_2 = RNNTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences,\n",
    "#                            data_processor, embedding_matrix, 2, train_size=0.4)\n",
    "# tuner_obj_2 = rnn_tuner_2.tune(max_trials=5, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16f36592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [01h 15m 05s]\n",
      "val_sparse_categorical_accuracy: 0.818871796131134\n",
      "\n",
      "Best val_sparse_categorical_accuracy So Far: 0.9134358763694763\n",
      "Total elapsed time: 05h 09m 26s\n"
     ]
    }
   ],
   "source": [
    "# Run tuning for 3 stacked bidirectional RNNs\n",
    "rnn_tuner_3 = RNNTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences,\n",
    "                           data_processor, embedding_matrix, 3, train_size=0.4)\n",
    "tuner_obj_3 = rnn_tuner_3.tune(max_trials=5, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "629310d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run tuning for 4 stacked bidirectional RNNs\n",
    "# rnn_tuner_4 = RNNTaggerTuner(train_ds_handler.sentences, dev_ds_handler.sentences,\n",
    "#                            data_processor, embedding_matrix, 4, train_size=0.4)\n",
    "# tuner_obj_4 = rnn_tuner_4.tune(max_trials=5, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15a3773d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_layer_first': 0.2,\n",
       " 'gru_units_0': 256,\n",
       " 'dropout_layer_0': 0.2,\n",
       " 'gru_units_1': 96,\n",
       " 'dropout_layer_1': 0.1,\n",
       " 'gru_units_2': 256,\n",
       " 'dropout_layer_2': 0.5,\n",
       " 'dropout_layer_last': 0.1,\n",
       " 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the hyperparameters of the best tuner\n",
    "best_hyperparams = tuner_obj_3.get_best_hyperparameters()[0].values\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fd4e7",
   "metadata": {},
   "source": [
    "### RNN Modeling\n",
    "\n",
    "In this section the class RNNTagger is introduced. This class contains methods for:\n",
    "\n",
    "- fitting a model (constructing the best architecture from a dictionary)\n",
    "- plotting curves (train/dev loss and train/dev accuracy vs epochs)\n",
    "- generating a classification report (for the predictions) given a dataset.\n",
    "\n",
    "During training we monitor sparse categorical accuracy, loss and f1.\n",
    "A Metrics class (taken from the course labs) is responsible for recording f1, precision and recall on the dev (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c155fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics class is added as a callback during training\n",
    "# (taken from course labs but modified to work with 3D data)\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        predictions = self.model.predict(self.validation_data[0])\n",
    "        val_predict = np.argmax(predictions, axis=2)\n",
    "        val_targ = self.validation_data[1]\n",
    "        correct = []\n",
    "        predicted = []\n",
    "        \n",
    "        for sequence_idx in range(val_targ.shape[0]):\n",
    "            for word_idx in range(val_targ.shape[1]):\n",
    "                if val_targ[sequence_idx][word_idx] != 0:\n",
    "                    correct.append(val_targ[sequence_idx][word_idx])\n",
    "                    predicted.append(val_predict[sequence_idx][word_idx])\n",
    "\n",
    "        _val_f1 = f1_score(correct, predicted,average=\"weighted\")\n",
    "        _val_recall = recall_score(correct, predicted,average=\"weighted\")\n",
    "        _val_precision = precision_score(correct, predicted,average=\"weighted\")\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dc56fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger:\n",
    "    def __init__(self, data_processor, embedding_matrix, n_stacked):\n",
    "        self.data_processor = data_processor\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_dimensions = embedding_matrix.shape[-1]\n",
    "        self.n_stacked = n_stacked\n",
    "        self.num_classes = len(self.data_processor.tag_tokenizer.word_index) + 1\n",
    "\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "\n",
    "    def fit(self, train_sentences, dev_sentences, hyperparams):\n",
    "        train_X, train_y = data_processor.transform(train_sentences)\n",
    "        dev_X, dev_y = data_processor.transform(dev_sentences)\n",
    "\n",
    "        self.build_model(hyperparams)\n",
    "        \n",
    "        if not os.path.exists('./checkpoints'):\n",
    "            os.makedirs('./checkpoints')\n",
    "\n",
    "        checkpoint = ModelCheckpoint('checkpoints/rnn_pos_tagger.weights.h5',\n",
    "                                     monitor='val_f1',\n",
    "                                     mode='max', verbose=2,\n",
    "                                     save_best_only=True,\n",
    "                                     save_weights_only=True)\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=2,\n",
    "                                       restore_best_weights=True,\n",
    "                                       monitor='val_f1', mode='max')\n",
    "\n",
    "        self.history = self.model.fit(train_X, train_y,\n",
    "                                      validation_data=(dev_X, dev_y),\n",
    "                                      batch_size=128, epochs=100, shuffle=True,\n",
    "                                      callbacks=[Metrics(valid_data=(dev_X, dev_y)),\n",
    "                                                 checkpoint, early_stopping])\n",
    "        \n",
    "    def classification_report(self, dataset):\n",
    "        dataset_X, dataset_y = self.data_processor.transform(dataset)\n",
    "        predictions_proba = self.model.predict(dataset_X)\n",
    "        predictions_2d = np.argmax(predictions_proba, axis=2)\n",
    "\n",
    "        y_true = []\n",
    "        y_predicted = []\n",
    "        y_probabilities = []\n",
    "\n",
    "        # consolidate for each word\n",
    "        for sequence_idx in range(predictions_proba.shape[0]):\n",
    "            for word_idx in range(predictions_proba.shape[1]):\n",
    "                if dataset_y[sequence_idx][word_idx] != 0:\n",
    "                    y_true.append(dataset_y[sequence_idx][word_idx])\n",
    "                    y_predicted.append(predictions_2d[sequence_idx][word_idx])\n",
    "                    probabilities = predictions_proba[sequence_idx][word_idx]\n",
    "                    y_probabilities.append(probabilities)\n",
    "\n",
    "        # wrap results as numpy arrays\n",
    "        y_true = np.array(y_true)\n",
    "        y_predicted = np.array(y_predicted)\n",
    "        y_probabilities = np.array(y_probabilities)\n",
    "\n",
    "        class_ids = list(self.data_processor.tag_tokenizer.index_word.keys())\n",
    "        class_labels = list(self.data_processor.tag_tokenizer.index_word.values())\n",
    "\n",
    "        return EvaluationMetrics.classification_report(y_true, y_probabilities, y_predicted, \n",
    "                                                   class_ids, class_labels)\n",
    "\n",
    "    def plot_curves(self):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # summarize history for accuracy\n",
    "        axs[0].plot(self.history.history['sparse_categorical_accuracy'])\n",
    "        axs[0].plot(self.history.history['val_sparse_categorical_accuracy'])\n",
    "        axs[0].set_title('Model Accuracy (Sparse Categorical Accuracy)')\n",
    "        axs[0].set_ylabel('accuracy')\n",
    "        axs[0].set_xlabel('epoch')\n",
    "        axs[0].legend(['train', 'dev'], loc='upper left')\n",
    "        axs[0].set_xticks(range(1,len(self.history.history['sparse_categorical_accuracy'])+1,4))\n",
    "    \n",
    "        # summarize history for loss\n",
    "        axs[1].plot(self.history.history['loss'])\n",
    "        axs[1].plot(self.history.history['val_loss'])\n",
    "        axs[1].set_title('Model Loss (Sparse Categorical Cross-Entropy)')\n",
    "        axs[1].set_ylabel('loss')\n",
    "        axs[1].set_xlabel('epoch')\n",
    "        axs[1].legend(['train', 'dev'], loc='upper right')\n",
    "        axs[1].set_xticks(range(1,len(self.history.history['loss'])+1,4))\n",
    "    \n",
    "        # # space between the plots\n",
    "        plt.tight_layout()\n",
    "     \n",
    "        # show plot\n",
    "        plt.show()\n",
    "\n",
    "    def build_model(self, hyperparams):\n",
    "        self.model = Sequential()\n",
    "\n",
    "        self.model.add(Input(shape=(self.data_processor.max_sequence_length,)))\n",
    "        self.model.add(Embedding(self.data_processor.vocabulary_size,\n",
    "                                 self.embedding_dimensions,\n",
    "                                 weights=[self.embedding_matrix],\n",
    "                                 input_length=self.data_processor.max_sequence_length,\n",
    "                                 mask_zero=True, trainable=False))\n",
    "        \n",
    "        self.model.add(Dropout(hyperparams.get('dropout_layer_first')))\n",
    "\n",
    "        for i in range(0, self.n_stacked):\n",
    "            gru_units = hyperparams.get(\"gru_units_{}\".format(i))\n",
    "            dropout = hyperparams.get(\"dropout_layer_{}\".format(i))\n",
    "\n",
    "            self.model.add(Bidirectional(GRU(gru_units, return_sequences=True)))\n",
    "            self.model.add(Dropout(dropout))\n",
    "        \n",
    "        self.model.add(Dense(units=1_000, activation='relu'))\n",
    "        self.model.add(Dropout(hyperparams.get('dropout_layer_last')))\n",
    "\n",
    "        self.model.add(TimeDistributed(Dense(self.num_classes, activation='softmax')))\n",
    "\n",
    "        learning_rate = hyperparams.get('learning_rate')\n",
    "        self.model.compile(loss=sparse_categorical_crossentropy, \n",
    "                      optimizer=Adam(learning_rate=learning_rate),\n",
    "                      metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98450509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RNNTagger\n",
    "rnn_tagger = RNNTagger(data_processor, embedding_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b8aa8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 39s 791ms/step\n",
      " — val_f1: 0.842982 — val_precision: 0.844505 — val_recall: 0.847672\n",
      "\n",
      "Epoch 1: val_f1 improved from -inf to 0.84298, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 774s 10s/step - loss: 1.2099 - sparse_categorical_accuracy: 0.6152 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8477 - val_f1: 0.8430 - val_recall: 0.8477 - val_precision: 0.8445\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skgus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 35s 829ms/step\n",
      " — val_f1: 0.878746 — val_precision: 0.883162 — val_recall: 0.878851\n",
      "\n",
      "Epoch 2: val_f1 improved from 0.84298 to 0.87875, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 551s 7s/step - loss: 0.5048 - sparse_categorical_accuracy: 0.8334 - val_loss: 0.3559 - val_sparse_categorical_accuracy: 0.8789 - val_f1: 0.8787 - val_recall: 0.8789 - val_precision: 0.8832\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 35s 832ms/step\n",
      " — val_f1: 0.899212 — val_precision: 0.899619 — val_recall: 0.900226\n",
      "\n",
      "Epoch 3: val_f1 improved from 0.87875 to 0.89921, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 585s 8s/step - loss: 0.4020 - sparse_categorical_accuracy: 0.8663 - val_loss: 0.2864 - val_sparse_categorical_accuracy: 0.9002 - val_f1: 0.8992 - val_recall: 0.9002 - val_precision: 0.8996\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 35s 840ms/step\n",
      " — val_f1: 0.909870 — val_precision: 0.911317 — val_recall: 0.910564\n",
      "\n",
      "Epoch 4: val_f1 improved from 0.89921 to 0.90987, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 576s 8s/step - loss: 0.3476 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.2587 - val_sparse_categorical_accuracy: 0.9106 - val_f1: 0.9099 - val_recall: 0.9106 - val_precision: 0.9113\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 35s 838ms/step\n",
      " — val_f1: 0.915257 — val_precision: 0.917334 — val_recall: 0.914954\n",
      "\n",
      "Epoch 5: val_f1 improved from 0.90987 to 0.91526, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 589s 8s/step - loss: 0.3091 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.2415 - val_sparse_categorical_accuracy: 0.9150 - val_f1: 0.9153 - val_recall: 0.9150 - val_precision: 0.9173\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 36s 861ms/step\n",
      " — val_f1: 0.919820 — val_precision: 0.923513 — val_recall: 0.918400\n",
      "\n",
      "Epoch 6: val_f1 improved from 0.91526 to 0.91982, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 588s 8s/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9184 - val_f1: 0.9198 - val_recall: 0.9184 - val_precision: 0.9235\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 36s 847ms/step\n",
      " — val_f1: 0.923966 — val_precision: 0.926569 — val_recall: 0.923159\n",
      "\n",
      "Epoch 7: val_f1 improved from 0.91982 to 0.92397, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 597s 8s/step - loss: 0.2558 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.2204 - val_sparse_categorical_accuracy: 0.9232 - val_f1: 0.9240 - val_recall: 0.9232 - val_precision: 0.9266\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 36s 847ms/step\n",
      " — val_f1: 0.925088 — val_precision: 0.926795 — val_recall: 0.924308\n",
      "\n",
      "Epoch 8: val_f1 improved from 0.92397 to 0.92509, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 600s 8s/step - loss: 0.2323 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2124 - val_sparse_categorical_accuracy: 0.9243 - val_f1: 0.9251 - val_recall: 0.9243 - val_precision: 0.9268\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 36s 849ms/step\n",
      " — val_f1: 0.928094 — val_precision: 0.931737 — val_recall: 0.926687\n",
      "\n",
      "Epoch 9: val_f1 improved from 0.92509 to 0.92809, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 603s 8s/step - loss: 0.2172 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9267 - val_f1: 0.9281 - val_recall: 0.9267 - val_precision: 0.9317\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 36s 855ms/step\n",
      " — val_f1: 0.929607 — val_precision: 0.931283 — val_recall: 0.929272\n",
      "\n",
      "Epoch 10: val_f1 improved from 0.92809 to 0.92961, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 605s 8s/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.2011 - val_sparse_categorical_accuracy: 0.9293 - val_f1: 0.9296 - val_recall: 0.9293 - val_precision: 0.9313\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 36s 853ms/step\n",
      " — val_f1: 0.931552 — val_precision: 0.935070 — val_recall: 0.929723\n",
      "\n",
      "Epoch 11: val_f1 improved from 0.92961 to 0.93155, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 608s 8s/step - loss: 0.1927 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 0.9297 - val_f1: 0.9316 - val_recall: 0.9297 - val_precision: 0.9351\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 36s 861ms/step\n",
      " — val_f1: 0.928705 — val_precision: 0.934655 — val_recall: 0.926113\n",
      "\n",
      "Epoch 12: val_f1 did not improve from 0.93155\n",
      "75/75 [==============================] - 609s 8s/step - loss: 0.1797 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.2063 - val_sparse_categorical_accuracy: 0.9261 - val_f1: 0.9287 - val_recall: 0.9261 - val_precision: 0.9347\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 37s 887ms/step\n",
      " — val_f1: 0.932850 — val_precision: 0.934812 — val_recall: 0.932103\n",
      "\n",
      "Epoch 13: val_f1 improved from 0.93155 to 0.93285, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 619s 8s/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9418 - val_loss: 0.1956 - val_sparse_categorical_accuracy: 0.9321 - val_f1: 0.9329 - val_recall: 0.9321 - val_precision: 0.9348\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 37s 879ms/step\n",
      " — val_f1: 0.936169 — val_precision: 0.938745 — val_recall: 0.934851\n",
      "\n",
      "Epoch 14: val_f1 improved from 0.93285 to 0.93617, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 636s 8s/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9444 - val_loss: 0.1899 - val_sparse_categorical_accuracy: 0.9349 - val_f1: 0.9362 - val_recall: 0.9349 - val_precision: 0.9387\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 37s 870ms/step\n",
      " — val_f1: 0.934180 — val_precision: 0.937074 — val_recall: 0.932800\n",
      "\n",
      "Epoch 15: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 635s 8s/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.1913 - val_sparse_categorical_accuracy: 0.9328 - val_f1: 0.9342 - val_recall: 0.9328 - val_precision: 0.9371\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 37s 872ms/step\n",
      " — val_f1: 0.934700 — val_precision: 0.939570 — val_recall: 0.932390\n",
      "\n",
      "Epoch 16: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 636s 8s/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9498 - val_loss: 0.1992 - val_sparse_categorical_accuracy: 0.9324 - val_f1: 0.9347 - val_recall: 0.9324 - val_precision: 0.9396\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 37s 888ms/step\n",
      " — val_f1: 0.931189 — val_precision: 0.934886 — val_recall: 0.929108\n",
      "\n",
      "Epoch 17: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 640s 9s/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.2084 - val_sparse_categorical_accuracy: 0.9291 - val_f1: 0.9312 - val_recall: 0.9291 - val_precision: 0.9349\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 38s 903ms/step\n",
      " — val_f1: 0.936084 — val_precision: 0.938538 — val_recall: 0.934892\n",
      "\n",
      "Epoch 18: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 639s 9s/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.1928 - val_sparse_categorical_accuracy: 0.9349 - val_f1: 0.9361 - val_recall: 0.9349 - val_precision: 0.9385\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 36s 868ms/step\n",
      " — val_f1: 0.933176 — val_precision: 0.937920 — val_recall: 0.931200\n",
      "\n",
      "Epoch 19: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 639s 9s/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9312 - val_f1: 0.9332 - val_recall: 0.9312 - val_precision: 0.9379\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 36s 867ms/step\n",
      " — val_f1: 0.935178 — val_precision: 0.939144 — val_recall: 0.933169\n",
      "\n",
      "Epoch 20: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 631s 8s/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.2024 - val_sparse_categorical_accuracy: 0.9332 - val_f1: 0.9352 - val_recall: 0.9332 - val_precision: 0.9391\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 37s 872ms/step\n",
      " — val_f1: 0.934410 — val_precision: 0.939251 — val_recall: 0.932185\n",
      "\n",
      "Epoch 21: val_f1 did not improve from 0.93617\n",
      "75/75 [==============================] - 630s 8s/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9594 - val_loss: 0.2065 - val_sparse_categorical_accuracy: 0.9322 - val_f1: 0.9344 - val_recall: 0.9322 - val_precision: 0.9393\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 36s 862ms/step\n",
      " — val_f1: 0.938478 — val_precision: 0.940766 — val_recall: 0.937231\n",
      "\n",
      "Epoch 22: val_f1 improved from 0.93617 to 0.93848, saving model to checkpoints\\rnn_pos_tagger.weights.h5\n",
      "75/75 [==============================] - 626s 8s/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.1907 - val_sparse_categorical_accuracy: 0.9372 - val_f1: 0.9385 - val_recall: 0.9372 - val_precision: 0.9408\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 37s 876ms/step\n",
      " — val_f1: 0.936302 — val_precision: 0.940795 — val_recall: 0.934277\n",
      "\n",
      "Epoch 23: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 625s 8s/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9627 - val_loss: 0.2056 - val_sparse_categorical_accuracy: 0.9343 - val_f1: 0.9363 - val_recall: 0.9343 - val_precision: 0.9408\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 36s 858ms/step\n",
      " — val_f1: 0.936567 — val_precision: 0.940769 — val_recall: 0.934523\n",
      "\n",
      "Epoch 24: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 622s 8s/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9651 - val_loss: 0.2119 - val_sparse_categorical_accuracy: 0.9345 - val_f1: 0.9366 - val_recall: 0.9345 - val_precision: 0.9408\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 37s 871ms/step\n",
      " — val_f1: 0.934018 — val_precision: 0.940831 — val_recall: 0.930831\n",
      "\n",
      "Epoch 25: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 617s 8s/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.2255 - val_sparse_categorical_accuracy: 0.9308 - val_f1: 0.9340 - val_recall: 0.9308 - val_precision: 0.9408\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 36s 866ms/step\n",
      " — val_f1: 0.937356 — val_precision: 0.940780 — val_recall: 0.935590\n",
      "\n",
      "Epoch 26: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 622s 8s/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.2072 - val_sparse_categorical_accuracy: 0.9356 - val_f1: 0.9374 - val_recall: 0.9356 - val_precision: 0.9408\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 36s 861ms/step\n",
      " — val_f1: 0.935396 — val_precision: 0.939898 — val_recall: 0.933374\n",
      "\n",
      "Epoch 27: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 613s 8s/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9334 - val_f1: 0.9354 - val_recall: 0.9334 - val_precision: 0.9399\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 36s 859ms/step\n",
      " — val_f1: 0.937671 — val_precision: 0.940315 — val_recall: 0.936205\n",
      "\n",
      "Epoch 28: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 613s 8s/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9362 - val_f1: 0.9377 - val_recall: 0.9362 - val_precision: 0.9403\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 36s 860ms/step\n",
      " — val_f1: 0.938187 — val_precision: 0.940200 — val_recall: 0.937149\n",
      "\n",
      "Epoch 29: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 613s 8s/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.2171 - val_sparse_categorical_accuracy: 0.9371 - val_f1: 0.9382 - val_recall: 0.9371 - val_precision: 0.9402\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 36s 867ms/step\n",
      " — val_f1: 0.935287 — val_precision: 0.942410 — val_recall: 0.932349\n",
      "\n",
      "Epoch 30: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 614s 8s/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.2393 - val_sparse_categorical_accuracy: 0.9323 - val_f1: 0.9353 - val_recall: 0.9323 - val_precision: 0.9424\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 36s 855ms/step\n",
      " — val_f1: 0.936017 — val_precision: 0.938914 — val_recall: 0.934605\n",
      "\n",
      "Epoch 31: val_f1 did not improve from 0.93848\n",
      "75/75 [==============================] - 615s 8s/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.2203 - val_sparse_categorical_accuracy: 0.9346 - val_f1: 0.9360 - val_recall: 0.9346 - val_precision: 0.9389\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 36s 863ms/step\n",
      " — val_f1: 0.936732 — val_precision: 0.940780 — val_recall: 0.934605\n",
      "\n",
      "Epoch 32: val_f1 did not improve from 0.93848\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "75/75 [==============================] - 615s 8s/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.2408 - val_sparse_categorical_accuracy: 0.9346 - val_f1: 0.9367 - val_recall: 0.9346 - val_precision: 0.9408\n",
      "Epoch 32: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the RNNTagger\n",
    "rnn_tagger.fit(train_ds_handler.sentences, dev_ds_handler.sentences,\n",
    "               tuner_obj_3.get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e4c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 128, 100)          1555700   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128, 100)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 128, 512)          549888    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128, 512)          0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 128, 192)          351360    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128, 192)          0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 128, 512)          691200    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128, 512)          0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128, 1000)         513000    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128, 1000)         0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 128, 19)           19019     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3680167 (14.04 MB)\n",
      "Trainable params: 2124467 (8.10 MB)\n",
      "Non-trainable params: 1555700 (5.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "rnn_tagger.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30582c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot performance graphs\n",
    "rnn_tagger.plot_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecd414",
   "metadata": {},
   "source": [
    "### Evaluate the RNN tagger on the training set (classification report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d65a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 266s 892ms/step\n"
     ]
    }
   ],
   "source": [
    "train_set = train_ds_handler.sentences\n",
    "train_classification_report_df, train_macro_average_df = rnn_tagger.classification_report(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bb3fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.979414</td>\n",
       "      <td>0.988349</td>\n",
       "      <td>0.983861</td>\n",
       "      <td>0.998650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.990276</td>\n",
       "      <td>0.989469</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>0.999326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>adp</td>\n",
       "      <td>0.992309</td>\n",
       "      <td>0.992181</td>\n",
       "      <td>0.992245</td>\n",
       "      <td>0.999668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pron</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>det</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>adj</td>\n",
       "      <td>0.970384</td>\n",
       "      <td>0.975077</td>\n",
       "      <td>0.972725</td>\n",
       "      <td>0.996441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>propn</td>\n",
       "      <td>0.980552</td>\n",
       "      <td>0.936117</td>\n",
       "      <td>0.957819</td>\n",
       "      <td>0.993897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>aux</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>0.996372</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.999823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>adv</td>\n",
       "      <td>0.972364</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.972735</td>\n",
       "      <td>0.997151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>cconj</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>part</td>\n",
       "      <td>0.994939</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>0.997084</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>num</td>\n",
       "      <td>0.992785</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.995909</td>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>sconj</td>\n",
       "      <td>0.965556</td>\n",
       "      <td>0.973943</td>\n",
       "      <td>0.969731</td>\n",
       "      <td>0.995750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>intj</td>\n",
       "      <td>0.932376</td>\n",
       "      <td>0.974969</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.994406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>x</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.963664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>sym</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.966790</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          1       noun   0.979414  0.988349  0.983861              0.998650\n",
       "1          2      punct   0.999824  0.999648  0.999736              1.000000\n",
       "2          3       verb   0.990276  0.989469  0.989873              0.999326\n",
       "3          4        adp   0.992309  0.992181  0.992245              0.999668\n",
       "4          5       pron   0.997536  0.997536  0.997536              0.999948\n",
       "5          6        det   0.998725  0.998725  0.998725              0.999983\n",
       "6          7        adj   0.970384  0.975077  0.972725              0.996441\n",
       "7          8      propn   0.980552  0.936117  0.957819              0.993897\n",
       "8          9        aux   0.997616  0.996372  0.996994              0.999823\n",
       "9         10        adv   0.972364  0.973107  0.972735              0.997151\n",
       "10        11      cconj   0.998333  1.000000  0.999166              0.999995\n",
       "11        12       part   0.994939  0.999238  0.997084              0.999990\n",
       "12        13        num   0.992785  0.999053  0.995909              0.999734\n",
       "13        14          _   1.000000  1.000000  1.000000              1.000000\n",
       "14        15      sconj   0.965556  0.973943  0.969731              0.995750\n",
       "15        16       intj   0.932376  0.974969  0.953197              0.994406\n",
       "16        17          x   0.906832  0.918239  0.912500              0.963664\n",
       "17        18        sym   0.949275  0.984962  0.966790              0.997381"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dba55bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978839</td>\n",
       "      <td>0.983166</td>\n",
       "      <td>0.980924</td>\n",
       "      <td>0.996434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.978839              0.983166          0.980924   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.996434  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_macro_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e43c96",
   "metadata": {},
   "source": [
    "### Evaluate the RNN tagger on the dev set (classification report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10afc115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 35s 842ms/step\n"
     ]
    }
   ],
   "source": [
    "dev_set = dev_ds_handler.sentences\n",
    "dev_classification_report_df, dev_macro_average_df = rnn_tagger.classification_report(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbf6c083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.907426</td>\n",
       "      <td>0.910854</td>\n",
       "      <td>0.973179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.998116</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>0.999863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.946999</td>\n",
       "      <td>0.907733</td>\n",
       "      <td>0.926950</td>\n",
       "      <td>0.979092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>adp</td>\n",
       "      <td>0.960036</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.965610</td>\n",
       "      <td>0.994074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pron</td>\n",
       "      <td>0.989478</td>\n",
       "      <td>0.990347</td>\n",
       "      <td>0.989912</td>\n",
       "      <td>0.998834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>det</td>\n",
       "      <td>0.993664</td>\n",
       "      <td>0.992616</td>\n",
       "      <td>0.993140</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>adj</td>\n",
       "      <td>0.878396</td>\n",
       "      <td>0.857323</td>\n",
       "      <td>0.867732</td>\n",
       "      <td>0.944739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>propn</td>\n",
       "      <td>0.717412</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.725349</td>\n",
       "      <td>0.829490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>aux</td>\n",
       "      <td>0.988192</td>\n",
       "      <td>0.989653</td>\n",
       "      <td>0.988922</td>\n",
       "      <td>0.999422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>adv</td>\n",
       "      <td>0.906223</td>\n",
       "      <td>0.898349</td>\n",
       "      <td>0.902269</td>\n",
       "      <td>0.960811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>cconj</td>\n",
       "      <td>0.986811</td>\n",
       "      <td>0.993961</td>\n",
       "      <td>0.990373</td>\n",
       "      <td>0.999374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>part</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.980333</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.998395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>num</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.917679</td>\n",
       "      <td>0.955931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>0.992350</td>\n",
       "      <td>0.997851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>sconj</td>\n",
       "      <td>0.897574</td>\n",
       "      <td>0.824257</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.926089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>intj</td>\n",
       "      <td>0.545679</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.668684</td>\n",
       "      <td>0.884960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>x</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.361653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>sym</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.780355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          1       noun   0.914307  0.907426  0.910854              0.973179\n",
       "1          2      punct   0.998116  0.999371  0.998743              0.999863\n",
       "2          3       verb   0.946999  0.907733  0.926950              0.979092\n",
       "3          4        adp   0.960036  0.971249  0.965610              0.994074\n",
       "4          5       pron   0.989478  0.990347  0.989912              0.998834\n",
       "5          6        det   0.993664  0.992616  0.993140              0.999767\n",
       "6          7        adj   0.878396  0.857323  0.867732              0.944739\n",
       "7          8      propn   0.717412  0.733463  0.725349              0.829490\n",
       "8          9        aux   0.988192  0.989653  0.988922              0.999422\n",
       "9         10        adv   0.906223  0.898349  0.902269              0.960811\n",
       "10        11      cconj   0.986811  0.993961  0.990373              0.999374\n",
       "11        12       part   0.978852  0.980333  0.979592              0.998395\n",
       "12        13        num   0.952381  0.885417  0.917679              0.955931\n",
       "13        14          _   0.986957  0.997802  0.992350              0.997851\n",
       "14        15      sconj   0.897574  0.824257  0.859355              0.926089\n",
       "15        16       intj   0.545679  0.863281  0.668684              0.884960\n",
       "16        17          x   0.090909  0.333333  0.142857              0.361653\n",
       "17        18        sym   0.687500  0.733333  0.709677              0.780355"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e35a8ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856638</td>\n",
       "      <td>0.881069</td>\n",
       "      <td>0.86278</td>\n",
       "      <td>0.921327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.856638              0.881069           0.86278   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.921327  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_macro_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223f1f0",
   "metadata": {},
   "source": [
    "### Evaluate the RNN tagger on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "add54839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 34s 835ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set = test_ds_handler.sentences\n",
    "test_classification_report_df, test_macro_average_df = rnn_tagger.classification_report(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b826c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Id</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision-Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.892647</td>\n",
       "      <td>0.896438</td>\n",
       "      <td>0.894539</td>\n",
       "      <td>0.962878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.948187</td>\n",
       "      <td>0.886199</td>\n",
       "      <td>0.916145</td>\n",
       "      <td>0.973973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>adp</td>\n",
       "      <td>0.962331</td>\n",
       "      <td>0.979024</td>\n",
       "      <td>0.970606</td>\n",
       "      <td>0.993801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pron</td>\n",
       "      <td>0.988578</td>\n",
       "      <td>0.991409</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>det</td>\n",
       "      <td>0.991489</td>\n",
       "      <td>0.993368</td>\n",
       "      <td>0.992428</td>\n",
       "      <td>0.999526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>adj</td>\n",
       "      <td>0.853277</td>\n",
       "      <td>0.874846</td>\n",
       "      <td>0.863927</td>\n",
       "      <td>0.940753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>propn</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.730627</td>\n",
       "      <td>0.736288</td>\n",
       "      <td>0.835220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>aux</td>\n",
       "      <td>0.981621</td>\n",
       "      <td>0.988225</td>\n",
       "      <td>0.984912</td>\n",
       "      <td>0.998555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>adv</td>\n",
       "      <td>0.918406</td>\n",
       "      <td>0.868941</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>0.956356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>cconj</td>\n",
       "      <td>0.994055</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>part</td>\n",
       "      <td>0.975096</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.977906</td>\n",
       "      <td>0.997125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>num</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.843182</td>\n",
       "      <td>0.891827</td>\n",
       "      <td>0.934229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.996760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>sconj</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.860987</td>\n",
       "      <td>0.933106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>intj</td>\n",
       "      <td>0.484642</td>\n",
       "      <td>0.871166</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.880726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>x</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.349436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>sym</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.743393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Id Class Name  Precision    Recall        F1  Precision-Recall AUC\n",
       "0          1       noun   0.892647  0.896438  0.894539              0.962878\n",
       "1          2      punct   0.998350  0.999339  0.998844              0.999985\n",
       "2          3       verb   0.948187  0.886199  0.916145              0.973973\n",
       "3          4        adp   0.962331  0.979024  0.970606              0.993801\n",
       "4          5       pron   0.988578  0.991409  0.989991              0.999407\n",
       "5          6        det   0.991489  0.993368  0.992428              0.999526\n",
       "6          7        adj   0.853277  0.874846  0.863927              0.940753\n",
       "7          8      propn   0.742036  0.730627  0.736288              0.835220\n",
       "8          9        aux   0.981621  0.988225  0.984912              0.998555\n",
       "9         10        adv   0.918406  0.868941  0.892989              0.956356\n",
       "10        11      cconj   0.994055  0.997613  0.995831              0.999810\n",
       "11        12       part   0.975096  0.980732  0.977906              0.997125\n",
       "12        13        num   0.946429  0.843182  0.891827              0.934229\n",
       "13        14          _   0.961424  0.996923  0.978852              0.996760\n",
       "14        15      sconj   0.872727  0.849558  0.860987              0.933106\n",
       "15        16       intj   0.484642  0.871166  0.622807              0.880726\n",
       "16        17          x   0.223881  0.468750  0.303030              0.349436\n",
       "17        18        sym   0.735294  0.714286  0.724638              0.743393"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7baffe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro Average Precision</th>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <th>Macro Average F1</th>\n",
       "      <th>Macro Average Precision Recall AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859471</td>\n",
       "      <td>0.885035</td>\n",
       "      <td>0.866475</td>\n",
       "      <td>0.916391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Macro Average Precision  Macro Average Recall  Macro Average F1  \\\n",
       "0                 0.859471              0.885035          0.866475   \n",
       "\n",
       "   Macro Average Precision Recall AUC  \n",
       "0                            0.916391  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_macro_average_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
